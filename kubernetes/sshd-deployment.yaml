apiVersion: apps/v1
kind: Deployment
metadata:
  name: sshd
spec:
  strategy:
    type: Recreate
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: sshd
  template:
    metadata:
      labels:
        app.kubernetes.io/name: sshd
    spec:
      terminationGracePeriodSeconds: 10
      initContainers:
      - name: init
        image: iameli/go-livepeer-ssh-server
        command: ["/bin/bash"]
        args: ["-c", "if [ ! -f /target/initialized ]; then
                      password=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 13 ; echo '');
                      echo \"root:$password\" | chpasswd;
                      echo \"Root password is: $password\";
                      sed -i -e 's/archive.ubuntu.com/mirror.deace.id/' /etc/apt/sources.list;
                      echo 'Acquire::http::Proxy \"http://10.134.98.2:3128\";' > /etc/apt/apt.conf.d/proxy.conf;
                      cp -ax / /target;
                      echo 'Initialization complete';
                      touch /target/initialized;
                      fi"]
        resources:
          requests:
            cpu: 1
            memory: 1Gi
        volumeMounts:
        - name: root-storage
          mountPath: /target

      containers:
      - name: sshd
        command: ["/usr/sbin/sshd"]
        args: ["-D"]
        tty: true
        image: iameli/go-livepeer-ssh-server
        ports:
          - name: sshd
            containerPort: 22
            protocol: TCP
        volumeMounts:
        - name: data-storage
          mountPath: /mnt/data
        - name: root-storage
          mountPath: /bin
          subPath: bin
        - name: root-storage
          mountPath: /boot
          subPath: boot
        - name: root-storage
          mountPath: /etc
          subPath: etc
        - name: root-storage
          mountPath: /home
          subPath: home
        - name: root-storage
          mountPath: /lib
          subPath: lib
        - name: root-storage
          mountPath: /lib64
          subPath: lib64
        - name: root-storage
          mountPath: /opt
          subPath: opt
        - name: root-storage
          mountPath: /root
          subPath: root
        - name: root-storage
          mountPath: /sbin
          subPath: sbin
        - name: root-storage
          mountPath: /srv
          subPath: srv
        - name: root-storage
          mountPath: /usr
          subPath: usr
        - name: root-storage
          mountPath: /var
          subPath: var
        - name: run-lock
          mountPath: /run/lock

        resources:
          requests:
            cpu: 1500m # The CPU unit is mili-cores. 500m is 0.5 cores
            memory: 4Gi
          limits:
            cpu: 7000m
            memory: 8Gi
            nvidia.com/gpu: 6
            # GPUs can only be allocated as a limit, which both reserves and limits the number of GPUs the Pod will have access to
            # Making individual Pods resource light is advantageous for bin-packing. Since this Pod is for general purpose interactive testing
            # we allocate 6 GPUs to it

      # Node affinity can be used to require / prefer the Pods to be scheduled on a node with a specific hardware type
      # No affinity allows scheduling on all hardware types that can fulfill the resource request.
      # In this example, without affinity, any NVIDIA GPU would be allowed to run the Pod.
      # Read more about affinity at: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
      affinity:
        nodeAffinity:
          # This will REQUIRE the Pod to be run on a system with a Pascal GPU
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu.nvidia.com/class
                operator: In
                values:
                  - NV_Pascal
              - key: failure-domain.beta.kubernetes.io/region
                operator: In
                values:
                  - ORD1

      volumes:
        - name: root-storage
          persistentVolumeClaim:
            claimName: sshd-root-pv-claim
        - name: data-storage
          persistentVolumeClaim:
            claimName: sshd-data-pv-claim
        - name: run-lock
          emptyDir:
            medium: Memory
      restartPolicy: Always
